import os
import requests
import pandas as pd
from datetime import datetime
import gzip
import json

# Directory to store the updated files
base_directory = 'Updated_Database'

if not os.path.exists(base_directory):
    os.makedirs(base_directory)

def download_file(url, save_path):
    response = requests.get(url)
    response.raise_for_status()  # Check if the request was successful
    with open(save_path, 'wb') as file:
        file.write(response.content)
    print(f"Downloaded: {save_path}")

def update_cve():
    url = "https://nvd.nist.gov/feeds/json/cve/1.1/nvdcve-1.1-modified.json.gz"
    save_path = os.path.join(base_directory, f"cve_{datetime.now().strftime('%Y-%m-%d')}.json.gz")
    csv_save_path = os.path.join(base_directory, f"cve_{datetime.now().strftime('%Y-%m-%d')}.csv")
    download_file(url, save_path)

    # Unzip and load JSON
    with gzip.open(save_path, 'rt', encoding='utf-8') as f:
        data = json.load(f)

    # Parse JSON and convert to DataFrame
    cve_items = data['CVE_Items']
    cve_data = []
    for item in cve_items:
        cve_id = item['cve']['CVE_data_meta']['ID']
        description = item['cve']['description']['description_data'][0]['value']
        published_date = item['publishedDate']
        last_modified_date = item['lastModifiedDate']
        cve_data.append([cve_id, description, published_date, last_modified_date])

    df = pd.DataFrame(cve_data, columns=['CVE_ID', 'Description', 'PublishedDate', 'LastModifiedDate'])
    df.to_csv(csv_save_path, index=False)
    print(f"Saved CVE data to CSV: {csv_save_path}")

def update_exploitdb():
    url = "https://gitlab.com/exploit-database/exploitdb/-/archive/main/exploitdb-main.zip"
    save_path = os.path.join(base_directory, f"exploitdb_{datetime.now().strftime('%Y-%m-%d')}.zip")
    csv_save_path = os.path.join(base_directory, f"exploitdb_{datetime.now().strftime('%Y-%m-%d')}.csv")
    download_file(url, save_path)

    # Extract and convert to CSV
    # You will need to implement extraction and parsing of the data
    # For demonstration, the conversion part is not fully implemented
    # df = pd.DataFrame(data)  # Replace with actual data extraction logic
    # df.to_csv(csv_save_path, index=False)
    print(f"Saved ExploitDB data to CSV: {csv_save_path}")

def update_openvas():
    url = "https://actual-url-for-openvas-data"  # Replace with actual URL
    save_path = os.path.join(base_directory, f"openvas_{datetime.now().strftime('%Y-%m-%d')}.json")
    csv_save_path = os.path.join(base_directory, f"openvas_{datetime.now().strftime('%Y-%m-%d')}.csv")
    try:
        download_file(url, save_path)

        # Parse and convert to CSV
        # Implement the logic to parse the downloaded file and convert to CSV
        # df = pd.DataFrame(data)  # Replace with actual data extraction logic
        # df.to_csv(csv_save_path, index=False)
        print(f"Saved OpenVAS data to CSV: {csv_save_path}")
    except requests.exceptions.RequestException as e:
        print(f"Failed to update OpenVAS: {e}")

def update_scipvuldb():
    url = "https://vuldb.com/?api"  # Replace with actual API URL and parameters
    response = requests.post(url, json={"apikey": "your_api_key"})
    response.raise_for_status()
    csv_save_path = os.path.join(base_directory, f"scipvuldb_{datetime.now().strftime('%Y-%m-%d')}.csv")
    data = response.json()

    # Convert JSON to DataFrame
    df = pd.DataFrame(data)
    df.to_csv(csv_save_path, index=False)
    print(f"Saved SCIP VulDB data to CSV: {csv_save_path}")

def update_securitytracker():
    url = "https://www.securitytracker.com/rss/all.xml"
    save_path = os.path.join(base_directory, f"securitytracker_{datetime.now().strftime('%Y-%m-%d')}.xml")
    csv_save_path = os.path.join(base_directory, f"securitytracker_{datetime.now().strftime('%Y-%m-%d')}.csv")
    download_file(url, save_path)

    # Parse and convert to CSV
    # Implement the logic to parse the downloaded file and convert to CSV
    # df = pd.DataFrame(data)  # Replace with actual data extraction logic
    # df.to_csv(csv_save_path, index=False)
    print(f"Saved SecurityTracker data to CSV: {csv_save_path}")

def update_xforce():
    url = "https://exchange.xforce.ibmcloud.com/api/doc/"  # Replace with actual API URL and parameters
    try:
        response = requests.get(url)
        response.raise_for_status()
        csv_save_path = os.path.join(base_directory, f"xforce_{datetime.now().strftime('%Y-%m-%d')}.csv")
        data = response.json()

        # Convert JSON to DataFrame
        df = pd.DataFrame(data)
        df.to_csv(csv_save_path, index=False)
        print(f"Saved X-Force data to CSV: {csv_save_path}")
    except requests.exceptions.RequestException as e:
        print(f"Failed to update X-Force: {e}")

# Update functions for each database
update_functions = [
    update_cve,
    update_exploitdb,
    update_openvas,
    update_scipvuldb,
    update_securitytracker,
    update_xforce,
]

# Run the update functions
for update_function in update_functions:
    try:
        update_function()
    except Exception as e:
        print(f"Failed to update {update_function.__name__}: {e}")

print("All updates completed.")
